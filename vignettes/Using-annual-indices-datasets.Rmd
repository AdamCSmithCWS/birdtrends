---
title: "Use annual indices and uncertainty to estimate trends over time"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Use annual indices and uncertainty to estimate trends over time}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  #eval = FALSE,
  collapse = TRUE,
  comment = "#>"
)
```


We can use the `birdtrends` package to model trends overtime based on annual indices datasets. These include information on year of data, index, and some form of uncertainty. 

Note: this vignette assumes you had already followed the steps outlined [here](https://ninoxconsulting.github.io/birdtrends/articles/Getting_started.html)

## 1. Set-up

Lets start by loading all the libraries required.

```{r setup, warning = FALSE, message =FALSE}
library(birdtrends)
library(ggplot2)
library(mgcv)
library(dplyr)
library(tidyr)
```

## 2. Model the annual indices based on input data of observed annual indices. 

In many cases, we may not have access to the breadth of information retained in estimating the original modeled annual indices. 

An example data set is provided within this package. This is an annual estimate on the Pacific Wren (" "), generated using the [bbsBayes2](https://bbsbayes.github.io/bbsBayes2/) package. This data was kindly provided by A.C. Smith. 

```{r view input dataset}

head(annual_indicies_data)

```

In this example data set we have an annual index from 1968 to 2022, along with credible intervals of 2.5% and 97.5%. 

### 2.1 Fit a Bayesian Heirachial GAM (HGAM)

We can fit a hierarchical Bayesian General Additive Model (HGAM) to estimate the overall trend for the species over all years, or a specific date range. This model fits a smooth time-series function (i.e., the GAM) to the log-transformed annual estimates of relative abundance, while accounting for the uncertainty of each annual estimate (i.e., the Hierarchical aspect). This is a measurement-error model that assumes independence in the errors of each annual estimate. This independence assumption will be false for many sets of estimates (e.g., any estimates drawn from any model that includes some explicit temporal structure), but making this independence assumption is reasonable in the absence of a known autocorrelation structure in the annual errors. 


```{r run_hgam, warning = FALSE, message =FALSE}

indat1 <- annual_indicies_data

fitted_data <- fit_hgam(indat1, start_yr = NA, end_yr = NA, n_knots = NA)
#fitted_data <- fit_hgam(indat1, start_yr = 1990, end_yr = 2014, n_knots = NA)

```

### 2.2 Explore the results

Select a subset of all the fitted HGAM models and reformat to long format. 
In this example we selected 100 rows for simplicity. 


```{r reformat fitted data from hgam}

sel_hgams <- fitted_data %>%
  dplyr::slice_sample(., n = 100) %>%  
  dplyr::mutate(draw = seq(1, 100, 1)) %>% 
  tidyr::pivot_longer(., cols = !starts_with("d")) |> 
  dplyr::mutate(yearn = as.integer(name) - min(as.integer(name)))
         
```

We can reformat our original data to use in the plot 

```{r}

min_year <- as.numeric(min(sel_hgams$name))
max_year <- as.numeric(max(sel_hgams$name))

indat1 <- indat1 |> 
  filter(year >= min_year & year <= max_year)%>%
  dplyr::mutate(yearn = as.integer(year) - min(as.integer(year)))  

```

Now we can plot the predicted posterior distributions of 100 draws, along with the raw annual indices data provided. 

```{r}
comp_plot <- ggplot2::ggplot(data = sel_hgams,
                    ggplot2::aes(x = yearn,y = value,
                        group = draw, colour = draw))+
  ggplot2::geom_pointrange(data = indat1,
                  ggplot2::aes(x = yearn, y = index,
                      ymin = index_q_0.025,
                      ymax = index_q_0.975),
                  inherit.aes = FALSE,
                  alpha = 0.3)+
  ggplot2::geom_line(alpha = 0.3)+
  ggplot2::scale_colour_viridis_c() +
  ggplot2::scale_y_continuous(trans = "log10")+
  ggplot2::theme_bw()

```

```{r, fig.width=5, fig.height= 5}
comp_plot

```


## 3. Estimate trends

We can use our modeled values to estimate a trend over a given period of time. This can be used to predict into the future. 

First we need to reformat our fitted data. We can modify the object 'sel_hgams' above or reformat the raw output. 

We will convert our data to long form, with the following columns "draw", "year", and "proj_y". Note if using the output from the "fit_hgam" we can use the code below. 

```{r estimate trends}

ldf <- tibble::rowid_to_column(fitted_data, "draw") %>%
    tidyr::pivot_longer(., cols = !starts_with("d")) %>%
    dplyr::rename('year' = name, "proj_y" = value)%>%
    mutate(year = as.integer(year))

```

This creates a dataset in which each row contains an estimated indices per year and per posterior draw (n = 4000). 

```{r}
head(ldf)

```


Now we can estimate a trend based on a given time internal and method of estimating trends. 
Where no dates are specified, the minimum and maximum years will be used. Two methods are available to estimate trends; 1) Geometric mean and 2) Linear regression. 


```{r}

trend_sm <- get_trend(ldf, start_yr = 2014, end_yr = 2022, method = "gmean")

```

```{r}
head(trend_sm)

```

We can summarise the trend estimates to provide a median and confidence internal

```{r}
trend_sm |> 
  dplyr::mutate(trend_q0.025 = quantile(trend_log, 0.025),
         trend_q0.500 = quantile(trend_log,0.500),
         trend_q0.975 = quantile(trend_log,0.975)) |> 
  dplyr::select(c(trend_q0.025, trend_q0.500, trend_q0.975)) |> 
  distinct()

```

## 4. Predict trend

We can now use our modeled annual indices and estimated trends for our given years to predict into the future. 

```{r}
preds_sm <- predict_trend(ldf, trend_sm, start_yr = 2023, proj_yr = 2050)
```


```{r}
head(preds_sm)
```



## 5. Plot the prediction 

Now lets plot the results, to make a "pretty plot" we will use all the steps we worked through above. This includes 1) raw observed indices, 2) modeled indices, 3) predicted indices generated from our trends. 


```{r,  fig.width=7, fig.height= 5}

hgams_plot <- plot_trend(raw_indices = indat1, 
                          model_indices = ldf, 
                          pred_indices = preds_sm,
                          start_yr = 2014, 
                          end_yr = 2022)

```


## Additional targets and trend estimates 

We may also want to track how our predictions are tracking in relation to short term trends. For example species identified under the partners in flight have short and long term trends. 

For example we may identify a population change from a given time step (i.e. 2014) to a short and long term trend as a percentage change in population. 

For example we may have a short term target of 2024 with a range of -2% to 1% we can calculate what the annual index targets range will be. This can be added to our plots to identify the range we need to meet or how our predictions are tracking. 


```{r}

index_baseline <- get_targets(model_indices = ldf, 
                              ref_year = 2014, 
                              st_year = 2026, 
                              st_lu_target_pc = -2,
                              st_up_target_pc = 1, 
                              lt_year = 2046, 
                              lt_lu_target_pc = 5,
                              lt_up_target_pc = 10)

```




```{r,,  fig.width=7, fig.height= 5}

hgams_plot_target <- plot_trend(raw_indices = indat1, 
                          model_indices = ldf, 
                          pred_indices = preds_sm,
                          start_yr = 2014, 
                          end_yr = 2022, 
                          targets = index_baseline)
```


# Estimate confidence of reaching targets 

We can use the output of the trends to estimate uncertainty around meeting future trends. In the example above we can estimate the probability that we will meet our short- term or long-term targets. 

Our theoretical targets for the above example is short term (decrease of 2% to increase of 1%) and longterm target (2046) is (increase between 5 to 10% )


```{r}

prop_st <- calculate_probs(predicted_trends = preds_sm,
                ref_year = 2014, 
                targ_year = 2026, 
                prob_decrease = 2,
                prob_increase = 1)

prop_lt <- calculate_probs(predicted_trends = preds_sm,
                ref_year = 2014, 
                targ_year = 2046,
                prob_increase = c(5,10))


prop_st
prop_lt 


 
# predicted_trends = preds_sm
# calc_quantiles <- stats::quantile
# quantiles = c(0.025, 0.05, 0.25, 0.75, 0.95, 0.975)
# prob_decrease = c(0,2,50)
# prob_increase = c(0,2,50)
# 
# 
# 
# 
# calc_prob_crease <- function(x, p, type = "decrease") {
#   if(type == "decrease") f <- function(p) length(x[x < (-1 * p)]) / length(x)
#   if(type == "increase") f <- function(p) length(x[x > p]) / length(x)
#   
#   vapply(p, FUN = f, FUN.VALUE = 1.1) %>%
#     stats::setNames(paste0("prob_", type, "_", p, "_percent"))
# }
# 
# 
# 
# 
# # for each draw subtract target year from ref year (2024) - 2014
# aa <- filter(predicted_trends, year %in% c(2014, 2024)) |> 
#   select(-proj_y)
#   
# 
# aa <-  pivot_wider(aa, values_from = pred_ind, names_from = year)
# 
# ab <- aa |> 
#   mutate(ch = `2024`/`2014`) |> 
#   rowwise() |> 
#   mutate(ch_pc = 100 * (stats::median(ch) -1)) |> 
#   dplyr::ungroup() %>%
#   mutate(percent_change_ave = 100 * (stats::median(ch)-1),
#         #percent_change_q_0.025 = 100 *  (stats::quantile(ch, probs = 0.025)-1),
#         #percent_change_q_0.05 = 100 *  (stats::quantile(ch, probs = 0.05)-1),
#         #percent_change_q_0.25 = 100 *  (stats::quantile(ch, probs = 0.25)-1),
#         #percent_change_q_0.75 = 100 *  (stats::quantile(ch, probs = 0.75)-1),
#         #percent_change_q_0.95 = 100 *  (stats::quantile(ch, probs = 0.95)-1),
#         percent_change_q_0.975 = 100 *  (stats::quantile(ch, probs = 0.975)-1))
#  
#  
# 
# # Model conditional probabilities of population change during trends period
#   if(!is.null(prob_decrease)) {
#     ab <- ab %>%
#       dplyr::mutate(
#         pch_pp = purrr::map_df(.data$ch_pc, calc_prob_crease,
#                                .env$prob_decrease, type = "decrease")) %>%
#       tidyr::unnest("pch_pp") 
#   }
#   
#   if(!is.null(prob_increase)){
#     ab <- ab %>%
#       dplyr::mutate(
#         pch_pp = purrr::map_df(.data$ch_pc, calc_prob_crease,
#                                .env$prob_increase, type = "increase")) %>%
#       tidyr::unnest("pch_pp") 
#   }
#   
# 
# # filter and select only sections needed. 
#  
#  out <- ab |> 
#   mutate(across(starts_with("prob"), ~ sum(.x, na.rm = TRUE)/length(.x)*100)) %>% 
#   select(starts_with("p"))%>% 
#    distinct()
# 


```




